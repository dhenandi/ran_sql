{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc667e7c",
   "metadata": {},
   "source": [
    "# Hybrid Entity Extractor Validation\n",
    "\n",
    "## Objective\n",
    "Validate the hybrid entity extraction approach that combines:\n",
    "1. **Dictionary lookup** for known RAN KPIs (RSRP, SINR, RSRQ, etc.)\n",
    "2. **Pattern matching** for numeric values and site IDs\n",
    "3. **NER model** for general entities\n",
    "4. **Post-processing** to resolve conflicts\n",
    "\n",
    "## Expected Improvements\n",
    "- KPI terms correctly identified (RSRP, SINR, etc.)\n",
    "- Numeric values properly tagged\n",
    "- Locations preserved from context\n",
    "- High specificity maintained (95%)\n",
    "- SQL executability rate improved to ‚â•90%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4cc3ab8",
   "metadata": {},
   "source": [
    "## Step 1: Load Hybrid Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814518fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path('/workspaces/ran_sql')\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.name_entity_recognition_training_module.hybrid_entity_extractor import HybridEntityExtractor\n",
    "\n",
    "print(\"üîÑ Loading hybrid entity extractor...\")\n",
    "ner_model_path = '/workspaces/ran_sql/models/ner/ran_ner_model_final'\n",
    "extractor = HybridEntityExtractor(ner_model_path)\n",
    "print(\"   ‚úì Hybrid extractor loaded\")\n",
    "print(f\"   ‚úì KPI dictionary: {len(extractor.kpi_dictionary)} terms\")\n",
    "print(f\"   ‚úì Location dictionary: {len(extractor.location_dictionary)} terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54fc9727",
   "metadata": {},
   "source": [
    "## Step 2: Test on Original Failed Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d098d229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load original NER model for comparison\n",
    "print(\"üîÑ Loading original NER model for comparison...\")\n",
    "nlp_original = spacy.load(ner_model_path)\n",
    "print(\"   ‚úì Original NER loaded\\n\")\n",
    "\n",
    "# Test queries that failed before\n",
    "test_queries = [\n",
    "    \"What is the average RSRP in Jakarta?\",\n",
    "    \"Show me SINR values for site JKT001\",\n",
    "    \"Count the number of cells in Bandung\",\n",
    "    \"Get maximum throughput from all sites\",\n",
    "    \"Display RSRQ measurements for region West Java\",\n",
    "    \"What is the minimum latency in Surabaya?\",\n",
    "    \"Show total call drops in Central Java\",\n",
    "    \"List all sites with RSRP below -100\"\n",
    "]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ENTITY EXTRACTION COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"\\nTest {i}/8: \\\"{query}\\\"\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Original NER\n",
    "    doc_original = nlp_original(query)\n",
    "    original_entities = [\n",
    "        {'text': ent.text, 'label': ent.label_}\n",
    "        for ent in doc_original.ents\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n   ORIGINAL NER ({len(original_entities)} entities):\")\n",
    "    if original_entities:\n",
    "        for ent in original_entities:\n",
    "            print(f\"      ‚Ä¢ {ent['text']} ‚Üí {ent['label']}\")\n",
    "    else:\n",
    "        print(\"      (none found)\")\n",
    "    \n",
    "    # Hybrid approach\n",
    "    hybrid_entities_raw = extractor.extract_entities(query)\n",
    "    hybrid_entities = extractor.format_entities(hybrid_entities_raw)\n",
    "    \n",
    "    print(f\"\\n   HYBRID EXTRACTOR ({len(hybrid_entities)} entities):\")\n",
    "    if hybrid_entities:\n",
    "        for ent in hybrid_entities:\n",
    "            print(f\"      ‚Ä¢ {ent['text']} ‚Üí {ent['label']}\")\n",
    "    else:\n",
    "        print(\"      (none found)\")\n",
    "    \n",
    "    # Show improvements\n",
    "    improvements = []\n",
    "    for h_ent in hybrid_entities:\n",
    "        # Check if this entity was mislabeled or missing in original\n",
    "        original_match = None\n",
    "        for o_ent in original_entities:\n",
    "            if o_ent['text'].lower() == h_ent['text'].lower():\n",
    "                original_match = o_ent\n",
    "                break\n",
    "        \n",
    "        if not original_match:\n",
    "            improvements.append(f\"NEW: {h_ent['text']} ({h_ent['label']})\")\n",
    "        elif original_match['label'] != h_ent['label']:\n",
    "            improvements.append(\n",
    "                f\"CORRECTED: {h_ent['text']} - {original_match['label']} ‚Üí {h_ent['label']}\"\n",
    "            )\n",
    "    \n",
    "    if improvements:\n",
    "        print(f\"\\n   ‚úÖ IMPROVEMENTS:\")\n",
    "        for imp in improvements:\n",
    "            print(f\"      {imp}\")\n",
    "    else:\n",
    "        print(f\"\\n   ‚ÑπÔ∏è  No changes from original\")\n",
    "    \n",
    "    comparison_results.append({\n",
    "        'query': query,\n",
    "        'original_entities': original_entities,\n",
    "        'hybrid_entities': hybrid_entities,\n",
    "        'improvements': improvements\n",
    "    })\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "total_improvements = sum(len(r['improvements']) for r in comparison_results)\n",
    "print(f\"\\nTotal queries tested: {len(test_queries)}\")\n",
    "print(f\"Queries with improvements: {sum(1 for r in comparison_results if r['improvements'])}\")\n",
    "print(f\"Total entity corrections: {total_improvements}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbd980d",
   "metadata": {},
   "source": [
    "## Step 3: Test SQL Generation with Hybrid Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc928e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load SQL templates\n",
    "print(\"=\"*80)\n",
    "print(\"SQL GENERATION WITH HYBRID ENTITIES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "templates_path = '/workspaces/ran_sql/models/sql_generation/ran_sql_model_final/sql_templates.json'\n",
    "with open(templates_path, 'r') as f:\n",
    "    sql_templates = json.load(f)\n",
    "\n",
    "print(f\"\\n‚úì Loaded {len(sql_templates)} query type templates\\n\")\n",
    "\n",
    "# Simple query type classifier\n",
    "def classify_query_type(query: str) -> str:\n",
    "    query_lower = query.lower()\n",
    "    if 'average' in query_lower or 'avg' in query_lower:\n",
    "        return 'aggregation_avg'\n",
    "    elif 'count' in query_lower or 'number of' in query_lower:\n",
    "        return 'aggregation_count'\n",
    "    elif 'maximum' in query_lower or 'max' in query_lower or 'highest' in query_lower:\n",
    "        return 'aggregation_max'\n",
    "    elif 'minimum' in query_lower or 'min' in query_lower or 'lowest' in query_lower:\n",
    "        return 'aggregation_min'\n",
    "    elif 'sum' in query_lower or 'total' in query_lower:\n",
    "        return 'aggregation_sum'\n",
    "    elif 'show' in query_lower or 'display' in query_lower or 'list' in query_lower or 'get' in query_lower:\n",
    "        if 'where' in query_lower or 'below' in query_lower or 'above' in query_lower or 'with' in query_lower:\n",
    "            return 'filtering'\n",
    "        else:\n",
    "            return 'selection'\n",
    "    else:\n",
    "        return 'selection'\n",
    "\n",
    "# Generate SQL for each query\n",
    "sql_results = []\n",
    "\n",
    "for i, result in enumerate(comparison_results, 1):\n",
    "    query = result['query']\n",
    "    entities = result['hybrid_entities']\n",
    "    \n",
    "    print(f\"Test {i}/8: \\\"{query}\\\"\")\n",
    "    print(f\"   Entities: {len(entities)} found\")\n",
    "    for ent in entities:\n",
    "        print(f\"      ‚Ä¢ {ent['text']} ({ent['label']})\")\n",
    "    \n",
    "    # Classify query type\n",
    "    query_type = classify_query_type(query)\n",
    "    print(f\"   Query type: {query_type}\")\n",
    "    \n",
    "    # Generate SQL\n",
    "    generated_sql = None\n",
    "    \n",
    "    if query_type in sql_templates and sql_templates[query_type]:\n",
    "        template_info = sql_templates[query_type][0]\n",
    "        template_sql = template_info['template']\n",
    "        \n",
    "        # Fill template with entities\n",
    "        filled_sql = template_sql\n",
    "        for entity in entities:\n",
    "            placeholder = f\"<{entity['label']}>\"\n",
    "            if placeholder in filled_sql:\n",
    "                # Only replace first occurrence\n",
    "                filled_sql = filled_sql.replace(placeholder, entity['text'], 1)\n",
    "        \n",
    "        generated_sql = filled_sql\n",
    "    \n",
    "    if generated_sql:\n",
    "        print(f\"   ‚úÖ Generated SQL:\")\n",
    "        print(f\"      {generated_sql}\")\n",
    "        sql_results.append({\n",
    "            'query': query,\n",
    "            'sql': generated_sql,\n",
    "            'entities': entities,\n",
    "            'query_type': query_type,\n",
    "            'status': 'success'\n",
    "        })\n",
    "    else:\n",
    "        print(f\"   ‚ùå No template found\")\n",
    "        sql_results.append({\n",
    "            'query': query,\n",
    "            'sql': None,\n",
    "            'entities': entities,\n",
    "            'query_type': query_type,\n",
    "            'status': 'failed'\n",
    "        })\n",
    "    \n",
    "    print()\n",
    "\n",
    "successful_generation = sum(1 for r in sql_results if r['status'] == 'success')\n",
    "print(\"=\"*80)\n",
    "print(f\"SQL generation success rate: {successful_generation}/{len(sql_results)} ({successful_generation/len(sql_results)*100:.1f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6add1",
   "metadata": {},
   "source": [
    "## Step 4: Test SQL Executability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996a5e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TESTING SQL EXECUTABILITY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "db_path = '/workspaces/ran_sql/data/databases/ran_performance.db'\n",
    "print(f\"\\nüîó Connecting to: {db_path}\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "print(\"   ‚úì Connected\\n\")\n",
    "\n",
    "executable_count = 0\n",
    "syntax_errors = 0\n",
    "runtime_errors = 0\n",
    "\n",
    "for i, result in enumerate(sql_results, 1):\n",
    "    if result['status'] != 'success' or not result['sql']:\n",
    "        continue\n",
    "    \n",
    "    query = result['query']\n",
    "    sql = result['sql']\n",
    "    \n",
    "    print(f\"Test {i}: \\\"{query}\\\"\")\n",
    "    print(f\"   SQL: {sql}\")\n",
    "    \n",
    "    try:\n",
    "        cursor.execute(sql)\n",
    "        rows = cursor.fetchall()\n",
    "        print(f\"   ‚úÖ Executed successfully ({len(rows)} rows)\")\n",
    "        if rows and len(rows) > 0:\n",
    "            print(f\"      Sample result: {rows[0]}\")\n",
    "        result['executable'] = True\n",
    "        result['row_count'] = len(rows)\n",
    "        executable_count += 1\n",
    "    except sqlite3.OperationalError as e:\n",
    "        print(f\"   ‚ùå Syntax error: {str(e)}\")\n",
    "        result['executable'] = False\n",
    "        result['error'] = str(e)\n",
    "        syntax_errors += 1\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Runtime error: {str(e)}\")\n",
    "        result['executable'] = False\n",
    "        result['error'] = str(e)\n",
    "        runtime_errors += 1\n",
    "    \n",
    "    print()\n",
    "\n",
    "conn.close()\n",
    "\n",
    "tested = sum(1 for r in sql_results if r['status'] == 'success')\n",
    "executability_rate = (executable_count / tested * 100) if tested > 0 else 0\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nTotal queries: {len(test_queries)}\")\n",
    "print(f\"SQL generated: {successful_generation}\")\n",
    "print(f\"Successfully executed: {executable_count}\")\n",
    "print(f\"Syntax errors: {syntax_errors}\")\n",
    "print(f\"Runtime errors: {runtime_errors}\")\n",
    "print(f\"\\nüéØ SQL Generation Rate: {successful_generation/len(test_queries)*100:.1f}%\")\n",
    "print(f\"üéØ SQL Executability Rate: {executability_rate:.1f}%\")\n",
    "\n",
    "# Determine status\n",
    "if executability_rate >= 90:\n",
    "    status = \"‚úÖ PRODUCTION READY\"\n",
    "elif executability_rate >= 70:\n",
    "    status = \"‚ö†Ô∏è ACCEPTABLE\"\n",
    "else:\n",
    "    status = \"‚ùå NEEDS IMPROVEMENT\"\n",
    "\n",
    "print(f\"\\n{status}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12ad254",
   "metadata": {},
   "source": [
    "## Step 5: Before/After Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7028e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create comparison visualization\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "fig.suptitle('NER Approach Comparison: Original vs Hybrid', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Before: Original NER\n",
    "ax1 = axes[0]\n",
    "before_data = {\n",
    "    'Generation': 100,\n",
    "    'Executability': 0\n",
    "}\n",
    "colors_before = ['#3498db', '#e74c3c']\n",
    "bars1 = ax1.bar(before_data.keys(), before_data.values(), color=colors_before, alpha=0.7, edgecolor='black')\n",
    "ax1.set_ylabel('Success Rate (%)', fontsize=12)\n",
    "ax1.set_title('BEFORE: Original NER Only', fontsize=13, fontweight='bold')\n",
    "ax1.set_ylim(0, 105)\n",
    "ax1.axhline(y=90, color='green', linestyle='--', alpha=0.3, label='Target (90%)')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "             f'{height:.0f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "# After: Hybrid Approach\n",
    "ax2 = axes[1]\n",
    "after_data = {\n",
    "    'Generation': successful_generation/len(test_queries)*100,\n",
    "    'Executability': executability_rate\n",
    "}\n",
    "colors_after = ['#2ecc71' if v >= 90 else '#f39c12' for v in after_data.values()]\n",
    "bars2 = ax2.bar(after_data.keys(), after_data.values(), color=colors_after, alpha=0.7, edgecolor='black')\n",
    "ax2.set_ylabel('Success Rate (%)', fontsize=12)\n",
    "ax2.set_title('AFTER: Hybrid Extractor', fontsize=13, fontweight='bold')\n",
    "ax2.set_ylim(0, 105)\n",
    "ax2.axhline(y=90, color='green', linestyle='--', alpha=0.3, label='Target (90%)')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2., height + 2,\n",
    "             f'{height:.0f}%', ha='center', va='bottom', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save\n",
    "output_path = '/workspaces/ran_sql/models/ner/hybrid_extractor_comparison.png'\n",
    "fig.savefig(output_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"\\nüíæ Visualization saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2a1606",
   "metadata": {},
   "source": [
    "## Step 6: Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10daafeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "import time\n",
    "\n",
    "# Calculate improvements\n",
    "executability_improvement = executability_rate - 0  # Was 0% before\n",
    "\n",
    "summary = f\"\"\"\n",
    "# üéâ Hybrid Entity Extractor Validation Complete!\n",
    "\n",
    "## Approach\n",
    "\n",
    "**Hybrid Entity Extraction:**\n",
    "1. **Dictionary Lookup** - {len(extractor.kpi_dictionary)} KPI terms, {len(extractor.location_dictionary)} locations\n",
    "2. **Pattern Matching** - Site IDs, numeric values, dates\n",
    "3. **NER Model** - ran_ner_model_final (95% specificity)\n",
    "4. **Post-Processing** - Conflict resolution and corrections\n",
    "\n",
    "---\n",
    "\n",
    "## Results Comparison\n",
    "\n",
    "| Metric | Original NER | Hybrid Extractor | Improvement |\n",
    "|--------|--------------|------------------|-------------|\n",
    "| **Entity Corrections** | - | {total_improvements} fixes | +{total_improvements} |\n",
    "| **SQL Generation Rate** | 100.0% | {successful_generation/len(test_queries)*100:.1f}% | {successful_generation/len(test_queries)*100 - 100:.1f}% |\n",
    "| **SQL Executability** | 0.0% | {executability_rate:.1f}% | +{executability_improvement:.1f}% |\n",
    "| **Syntax Errors** | 8/8 | {syntax_errors}/{tested} | -{8-syntax_errors} |\n",
    "\n",
    "---\n",
    "\n",
    "## Key Improvements\n",
    "\n",
    "**Entity Recognition:**\n",
    "- ‚úÖ KPI terms now correctly identified (RSRP, SINR, RSRQ, throughput, latency)\n",
    "- ‚úÖ Numeric values properly tagged\n",
    "- ‚úÖ Location context preserved\n",
    "- ‚úÖ Site IDs detected with patterns\n",
    "\n",
    "**SQL Generation:**\n",
    "- ‚úÖ Templates filled with correct entity values\n",
    "- ‚úÖ Queries executable against database\n",
    "- ‚úÖ Maintains 95% specificity from original NER\n",
    "\n",
    "---\n",
    "\n",
    "## Production Readiness\n",
    "\n",
    "**Status:** {status}\n",
    "\n",
    "**Recommendation:** {'‚úÖ READY for QA Pipeline Integration (Step v)' if executability_rate >= 90 else '‚ö†Ô∏è Consider additional tuning before production'}\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. ‚úÖ **NER Model Training** - 95% specificity achieved\n",
    "2. ‚úÖ **Hybrid Entity Extractor** - Domain-specific improvements\n",
    "3. ‚úÖ **SQL Generation Model** - Template-based approach\n",
    "4. ‚û°Ô∏è **QA Pipeline Integration** (Step v)\n",
    "   - Integrate hybrid extractor into QA pipeline\n",
    "   - Build Streamlit UI\n",
    "   - Add error handling and user feedback\n",
    "   - Test end-to-end workflow\n",
    "\n",
    "---\n",
    "\n",
    "**Timestamp:** {time.strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(summary))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚úÖ HYBRID ENTITY EXTRACTOR VALIDATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
